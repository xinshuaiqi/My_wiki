# Course By James Zhou

# L4
# RNN
## limitations of CNN
- fixed input length

## LSTM: Long short term memory; a variant of RNN
- easier to retain longrange interactions.
- LSTM application: 
  - ehancer/TF prediction
  - ONT base calling


# L5 Auto encoder

# L6
regularization and optimization for deep learning
- Regularization—prevent overfitting
- - Early stopping
- - L2 regularization (aka weight decay)
- - Multi-task learning; data augmentation
- - Dropout

- Optimization—overcome underfitting
 - - SGD, SGD with momentum
 - - RMSProp

# L9 
DL: great power, but poor interpretability
* find important features in individual input examples
  * perturbation 不安；扰乱
  * backpropagate contribution
  * deconvolutional nets


# L13 **Protein Structure prediction**
- amino acid residues
- polypeptides
- Structure level
  - primary: AA seq
  - secondary: local 
    - alpha helix, beta sheet ...
  - Tertiary: 
  - Quaternary: 





